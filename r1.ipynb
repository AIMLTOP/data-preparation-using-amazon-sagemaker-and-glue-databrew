{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f600c-2b92-4ced-88fe-00cd4da5fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU sagemaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()  \n",
    "print(\"S3 bucket name: \", bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37224ced-8ad6-4f49-b3f2-47e781258d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"S3_BUCKET\"] = bucket\n",
    "\n",
    "!echo ${S3_BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a1902-a32f-4db4-970d-d8630f8a792d",
   "metadata": {},
   "source": [
    "Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f36c4-57c4-44c6-9fd0-2ebe42f93095",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp . s3://${S3_BUCKET}/data-preparation-using-amazon-sagemaker-and-glue-databrew --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862c8532-1198-49c1-b684-eb6f74d47bd1",
   "metadata": {},
   "source": [
    "Run the next code cell to get the pre-built Docker Image URL for scikit-learn container, stored in Amazon ECR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa77d61-da12-480b-8c0d-32daa46a32a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "region = boto3.session.Session().region_name\n",
    "accountRegionMap =\t{\n",
    "  \"us-west-1\": \"746614075791\",\"us-west-2\": \"246618743249\",\"us-east-1\": \"683313688378\",\n",
    "  \"us-east-2\": \"257758044811\",\"ap-northeast-1\": \"354813040037\",\"ap-northeast-2\": \"354813040037\",\n",
    "  \"ap-southeast-1\": \"121021644041\",\"ap-southeast-2\": \"783357654285\",\"ap-south-1\": \"720646828776\",\n",
    "  \"eu-west-1\": \"141502667606\",\"eu-west-2\": \"764974769150\",\"eu-central-1\": \"492215442770\",\"ca-central-1\": \"341280168497\"\n",
    "}\n",
    "\n",
    "account_id = accountRegionMap[region]\n",
    "ecr_repository = \"sagemaker-scikit-learn\"\n",
    "tag = \":0.23-1-cpu-py3\"\n",
    "\n",
    "uri_suffix = \"amazonaws.com\"\n",
    "if region in [\"cn-north-1\", \"cn-northwest-1\"]:\n",
    "    uri_suffix = \"amazonaws.com.cn\"\n",
    "ecr_repository_uri = \"{}.dkr.ecr.{}.{}/{}\".format(\n",
    "    account_id, region, uri_suffix, ecr_repository + tag\n",
    ")\n",
    "\n",
    "print(\"SageMaker processing repository uri: \", ecr_repository_uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb4406-acce-4e8e-afb6-9bc9bf29b1e8",
   "metadata": {},
   "source": [
    "On the Data Processing Step set the source and destination S3 URL for processing job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a189ae-d483-45fb-ad16-258f7ddd150a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 's3://'+bucket+'/data-preparation-using-amazon-sagemaker-and-glue-databrew/DataSet/insurance_claims.csv'\n",
    "destination = 's3://'+bucket+'/data-preparation-using-amazon-sagemaker-and-glue-databrew/Results/DataProcessing'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7325542-c717-4b77-bb7c-c5b671550f52",
   "metadata": {},
   "source": [
    "Run the next cell to generate the AutoInsuranceFraudProcessing.py file. All the processing steps are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ed1c6-cba6-4538-b6fd-0f0e193fb0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile AutoInsuranceFraudProcessing.py\n",
    "#This block of code generates a file \"AutoInsuranceFraudProcessing.py\" which has the code to process the data\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelBinarizer, KBinsDiscretizer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #get arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args, _ = parser.parse_known_args()\n",
    "    print(\"Received arguments {}\".format(args))\n",
    "    \n",
    "    #get the input data\n",
    "    input_data_path = os.path.join(\"/opt/ml/processing/input\", \"insurance_claims.csv\")\n",
    "    print(\"Reading input data from {}\".format(input_data_path))\n",
    "    df = pd.read_csv(input_data_path)\n",
    "    df = pd.DataFrame(data=df)\n",
    "    print(df.head())\n",
    "\n",
    "    #replacing ? with nan for the columns\n",
    "    df['police_report_available']=df['police_report_available'].replace('?',np.nan)\n",
    "    #dropping the unnecessary rows\n",
    "    df=df.dropna(subset=['police_report_available'])\n",
    "    \n",
    "    #drop unnecessary columns\n",
    "    df=df.drop(['months_as_customer'],axis=1)\n",
    "    \n",
    "    #now deal with the categorical features\n",
    "    #for the columns insured_sex and fraud_reported\n",
    "    le=LabelEncoder()\n",
    "    for i in list(df.columns):\n",
    "        if df[i].dtype=='object':\n",
    "            df[i]=le.fit_transform(df[i])\n",
    "    \n",
    "    #final preprocessed data\n",
    "    print(df.head())\n",
    "    train_features_output_path = os.path.join(\"/opt/ml/processing/output\", \"preprocessed_data.csv\")\n",
    "    df.to_csv(train_features_output_path, index=False)\n",
    "    print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557050a4-574d-42a1-a024-1b0eb0f88d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "script_processor = ScriptProcessor(command=['python3'],\n",
    "                                   image_uri=ecr_repository_uri,\n",
    "                                   role=role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.m5.2xlarge')\n",
    "\n",
    "script_processor.run(code='AutoInsuranceFraudProcessing.py',\n",
    "                     inputs=[ProcessingInput(source=source,\n",
    "                                             destination='/opt/ml/processing/input')],\n",
    "                     outputs=[ProcessingOutput(output_name=\"preprocessed_data.csv\", destination=destination,\n",
    "                                               source='/opt/ml/processing/output')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cffff4-b731-4c5b-aa6f-8898af76208f",
   "metadata": {},
   "source": [
    "You can view the job by going into the SageMaker console > Processing > Processing jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07c33c6-5e49-48a2-87c3-cf5fb8c63fed",
   "metadata": {},
   "source": [
    "Run the last cell to export the data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfb28e-04a7-4b3b-a8aa-829d8c8c1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_job_description = script_processor.jobs[-1].describe()\n",
    "\n",
    "output_config = preprocessing_job_description[\"ProcessingOutputConfig\"]\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    print(output)\n",
    "    preprocessed_data = output[\"S3Output\"][\"S3Uri\"]\n",
    "    print(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fafff8-acf8-4aae-83a6-969fa6c0f146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
